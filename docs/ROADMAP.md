# LCEngine Development Roadmap

> **é¡¹ç›®å®šä½**ï¼šé¢è¯•å±•ç¤ºçº§çš„å·¥ä¸š RAG+Agent ç³»ç»Ÿ
> **æ ¸å¿ƒç­–ç•¥**ï¼š70% Native å®ç°ï¼ˆå±•ç¤ºæ·±åº¦ï¼‰+ 30% æ¡†æ¶é›†æˆï¼ˆæé«˜æ•ˆç‡ï¼‰
> **æ—¶é—´è§„åˆ’**ï¼š3-4 å‘¨å®Œæˆ v0.2-v0.4 æ ¸å¿ƒåŠŸèƒ½

---

## ğŸ¯ æ€»ä½“ç›®æ ‡

1. **æŠ€æœ¯æ·±åº¦**ï¼šå±•ç¤ºå¯¹ RAG/Agent åº•å±‚åŸç†çš„æ·±å…¥ç†è§£
2. **å·¥ç¨‹èƒ½åŠ›**ï¼šå®Œæ•´çš„æµ‹è¯•ã€è¯„ä¼°ã€ç›‘æ§ä½“ç³»
3. **ä¸šåŠ¡ä»·å€¼**ï¼šæ¸…æ™°çš„å­¦ä¹ åŠ©æ‰‹åœºæ™¯ï¼Œè§£å†³çœŸå®é—®é¢˜
4. **å·®å¼‚åŒ–**ï¼šåˆ›æ–°çš„é•¿æœŸè®°å¿†æœºåˆ¶ + ç³»ç»ŸåŒ–çš„è´¨é‡è¯„ä¼°

---

## ğŸ“‹ ç‰ˆæœ¬è§„åˆ’æ€»è§ˆ

| ç‰ˆæœ¬ | æ ¸å¿ƒç›®æ ‡                    | æŠ€æœ¯é€‰å‹       | å·¥ä½œé‡ | é¢è¯•æƒé‡   | çŠ¶æ€      |
| ---- | --------------------------- | -------------- | ------ | ---------- | --------- |
| v0.1 | åŸºç¡€ RAG MVP                | 100% Native    | -      | â­â­â­     | âœ… å·²å®Œæˆ |
| v0.2 | è®°å¿† + FAISS + è¯„ä¼°         | 100% Native    | 5-7 å¤© | â­â­â­â­â­ | ğŸš§ è¿›è¡Œä¸­ |
| v0.3 | æ•°æ®æ¥å…¥ + æœç´¢ Agent       | æ··åˆç­–ç•¥       | 4-5 å¤© | â­â­â­â­   | ğŸ“… è®¡åˆ’ä¸­ |
| v0.4 | é«˜çº§æ£€ç´¢ï¼ˆHybrid + Rerankï¼‰ | 95% Native     | 5-6 å¤© | â­â­â­â­â­ | ğŸ“… è®¡åˆ’ä¸­ |
| v0.5 | å­¦ä¹ æ¨¡å¼ + å¤æ‚ç¼–æ’         | å¼•å…¥ LangGraph | 4-5 å¤© | â­â­â­     | ğŸ“… å¯é€‰   |
| v0.6 | ç›‘æ§ + æ•°æ®é—­ç¯             | é›†æˆå·¥å…·       | 3-4 å¤© | â­â­       | ğŸ“… å¯é€‰   |

**æ¨èæœ€å°å¯é¢è¯•ç‰ˆæœ¬**ï¼šv0.2 + v0.4ï¼ˆæ ¸å¿ƒ RAG è´¨é‡ï¼‰
**ç†æƒ³é¢è¯•ç‰ˆæœ¬**ï¼šv0.2 + v0.3 + v0.4ï¼ˆå®Œæ•´èƒ½åŠ›å±•ç¤ºï¼‰

---

## ğŸ“¦ v0.1 åŸºç¡€ RAG MVP âœ…

**çŠ¶æ€**ï¼šå·²å®Œæˆ
**æ ¸å¿ƒä»·å€¼**ï¼šæ‰“å¥½åŸºç¡€ï¼Œè¯æ˜å¯è¡Œæ€§

### å·²å®ç°åŠŸèƒ½

- âœ… Streamlit èŠå¤©ç•Œé¢
- âœ… PDF/TXT æ–‡æ¡£ä¸Šä¼ å’Œå¤„ç†
- âœ… åŸºäº NumPy çš„å‘é‡å­˜å‚¨
- âœ… OpenAI Embedding + Chat API é›†æˆ
- âœ… å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†
- âœ… å®Œæ•´çš„æµ‹è¯•è¦†ç›–ï¼ˆ85%+ï¼‰
- âœ… Pre-commit hooks + CI/CD

### æŠ€æœ¯æ ˆ

- **æ–‡æ¡£å¤„ç†**ï¼šPyPDF2 + è‡ªå®šä¹‰ chunking
- **å‘é‡å­˜å‚¨**ï¼šSQLite + NumPy/pickle
- **Embedding**ï¼šOpenAI text-embedding-3-small
- **LLM**ï¼šOpenAI gpt-4.1-nano-2025-04-14

### é¢è¯•è¯æœ¯å‡†å¤‡

> "æˆ‘ä»æœ€åŸºç¡€çš„å®ç°å¼€å§‹ï¼Œè‡ªå·±å†™äº†å‘é‡å­˜å‚¨å’Œæ£€ç´¢é€»è¾‘ã€‚è¿™è®©æˆ‘æ·±å…¥ç†è§£äº† embeddingã€cosine similarityã€chunking ç­–ç•¥ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚è™½ç„¶ v0.2 ä¼šå‡çº§åˆ° FAISSï¼Œä½†è¿™ä¸ªåŸºç¡€è®©æˆ‘èƒ½æ¸…æ™°è®²è§£å‘é‡æ£€ç´¢çš„æ•°å­¦åŸç†..."

---

## ğŸ”¥ v0.2 è®°å¿† + FAISS + è¯„ä¼°æ¡†æ¶ â­â­â­â­â­

**çŠ¶æ€**ï¼šğŸš§ è¿›è¡Œä¸­
**ä¼˜å…ˆçº§**ï¼šP0ï¼ˆæœ€é«˜ï¼‰
**å·¥ä½œé‡**ï¼š5-7 å¤©
**é¢è¯•æƒé‡**ï¼šâ­â­â­â­â­ï¼ˆæ ¸å¿ƒå±•ç¤ºç‰ˆæœ¬ï¼‰

### æ ¸å¿ƒç›®æ ‡

1. **å‘é‡å­˜å‚¨å‡çº§**ï¼šä» NumPy è¿ç§»åˆ° FAISSï¼ˆå·¥ä¸šçº§æ€§èƒ½ï¼‰
2. **é•¿æœŸè®°å¿†ç³»ç»Ÿ**ï¼šåˆ›æ–°çš„ç¬”è®°/é”™é¢˜æœºåˆ¶ï¼ˆå·®å¼‚åŒ–äº®ç‚¹ï¼‰
3. **è¯„ä¼°æ¡†æ¶å»ºç«‹**ï¼šRAGAS + è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆå·¥ç¨‹èƒ½åŠ›ä½“ç°ï¼‰

### æŠ€æœ¯é€‰å‹ï¼š100% Native

#### å®ç°æ¸…å•

**PR1: FAISS é›†æˆä¸æ•°æ®å±‚** (2-3 å¤©)

- [ ] æ–°å»º `app/vector_store/faiss_store.py`
  - å°è£… FAISS IndexFlatIP ç´¢å¼•
  - å®ç°ä¸ SQLiteVectorStore ç»Ÿä¸€çš„æ¥å£
  - metadata æŒä¹…åŒ–åˆ° SQLite
- [ ] å·¥å‚æ¨¡å¼ï¼š`app/vector_store/__init__.py`
  ```python
  def get_vector_store(backend: Literal["faiss", "sqlite"]) -> VectorStore:
      if backend == "faiss":
          return FaissVectorStore(...)
      return SQLiteVectorStore(...)
  ```
- [ ] é…ç½®è¿ç§»
  - æ–°å¢ `VECTOR_BACKEND` ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤"faiss"ï¼‰
  - ä¿ç•™ `VECTOR_STORE_DB_PATH` å‘åå…¼å®¹
  - æ–°å¢ `FAISS_INDEX_PATH = data/faiss/index.faiss`
- [ ] æ•°æ®åº“ Schema æ‰©å±•

  ```sql
  -- æ‰©å±•chunksè¡¨
  ALTER TABLE chunks ADD COLUMN doc_type TEXT CHECK(doc_type IN ('document','note','mistake'));
  ALTER TABLE chunks ADD COLUMN topic TEXT;
  ALTER TABLE chunks ADD COLUMN created_at DATETIME DEFAULT CURRENT_TIMESTAMP;
  ALTER TABLE chunks ADD COLUMN user TEXT;

  -- æ–°å»ºlabelsè¡¨
  CREATE TABLE labels(
      chunk_id INTEGER,
      label TEXT,
      FOREIGN KEY(chunk_id) REFERENCES chunks(id)
  );
  CREATE INDEX idx_labels_label ON labels(label);
  ```

- [ ] å•å…ƒæµ‹è¯•
  - FAISS store CRUD æ“ä½œ
  - metadata è¿‡æ»¤æŸ¥è¯¢
  - æŒä¹…åŒ–å’ŒåŠ è½½
  - æ€§èƒ½ benchmarkï¼ˆ10k chunksï¼‰

**PR2: é•¿æœŸè®°å¿†ä¸ UI é›†æˆ** (2-3 å¤©)

- [ ] æ‰©å±• `DocumentChunk` æ¨¡å‹
  ```python
  @dataclass
  class DocumentChunk:
      # åŸæœ‰å­—æ®µ...
      doc_type: str = "document"  # document | note | mistake
      topic: Optional[str] = None
      labels: list[str] = field(default_factory=list)
      created_at: datetime = field(default_factory=datetime.now)
  ```
- [ ] è®°å¿†ä¿å­˜åŠŸèƒ½
  - UI æŒ‰é’®ï¼š"ä¿å­˜ä¸ºç¬”è®°" / "æ ‡è®°ä¸ºé”™é¢˜"
  - å¯é€‰ LLM ç²¾ç‚¼ï¼ˆç”Ÿæˆ refined_question/answer/explanationï¼‰
  - å†™å…¥ vector store + æ ‡è®° metadata
- [ ] æ£€ç´¢åŠ æƒæœºåˆ¶ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
  ```python
  def weighted_retrieval(chunks, query, bias=0.05):
      """ç¬”è®°/é”™é¢˜åœ¨æ£€ç´¢æ—¶åŠ æƒ+0.05"""
      for chunk in chunks:
          if chunk.doc_type in ['note', 'mistake']:
              chunk.score += bias
      return sorted(chunks, key=lambda x: x.score, reverse=True)
  ```
- [ ] UI æ”¹è¿›
  - Sidebar æ˜¾ç¤ºå¤–ç½‘æœç´¢å¼€å…³ï¼ˆå ä½ï¼Œv0.3 å®ç°ï¼‰
  - æ˜¾ç¤ºå‘é‡åº“ç»Ÿè®¡ï¼ˆæ–‡æ¡£æ•°/ç¬”è®°æ•°/é”™é¢˜æ•°ï¼‰
  - Debug åŒºå±•ç¤º doc_type/topic/created_at
- [ ] é›†æˆæµ‹è¯•
  - ç«¯åˆ°ç«¯æµç¨‹ï¼šä¸Šä¼ æ–‡æ¡£ â†’ æé—® â†’ ä¿å­˜ç¬”è®° â†’ å†æ¬¡æ£€ç´¢å‘½ä¸­

**PR3: è¯„ä¼°å·¥å…·é“¾** (1-2 å¤©)

- [ ] åˆ›å»º `evaluate.py` è„šæœ¬
  ```bash
  python evaluate.py \
      --dataset tests/data/evaluation_dataset.json \
      --k 5 \
      --vector-backend faiss \
      --output data/eval_runs/$(date +%Y%m%d_%H%M%S).json
  ```
- [ ] å®ç°æŒ‡æ ‡
  - **Hit@k**ï¼šæ£€ç´¢æ˜¯å¦å‘½ä¸­æ­£ç¡®æ–‡æ¡£
  - **RAGAS**ï¼š
    - Faithfulnessï¼ˆé˜²å¹»è§‰ï¼‰
    - Context Precision/Recallï¼ˆæ£€ç´¢è´¨é‡ï¼‰
    - Answer Relevancyï¼ˆå›ç­”ç›¸å…³æ€§ï¼‰
  - **P95 Latency**ï¼šæ€§èƒ½æŒ‡æ ‡
  - **Cost Tracking**ï¼šAPI è°ƒç”¨æˆæœ¬
- [ ] è¾“å‡ºæ ¼å¼
  ```json
  {
    "timestamp": "2025-01-15T10:30:00",
    "config": {"model": "gpt-4.1-nano", "k": 5, "backend": "faiss"},
    "metrics": {
      "hit_at_5": 0.82,
      "ragas_faithfulness": 0.88,
      "p95_latency_ms": 1200,
      "avg_cost_per_query": 0.003
    },
    "details": [...]
  }
  ```
- [ ] Baseline å»ºç«‹
  - è¿è¡Œ v0.1 é…ç½®ä½œä¸º baseline
  - è¿è¡Œ v0.2 é…ç½®å¯¹æ¯”æå‡
  - è®°å½•åˆ° `docs/experiments.md`

### æˆåŠŸæŒ‡æ ‡

- âœ… FAISS æ£€ç´¢å»¶è¿Ÿ < NumPyï¼ˆ10k chunks åœºæ™¯ä¸‹ <200msï¼‰
- âœ… é•¿æœŸè®°å¿†å‘½ä¸­ç‡ > æ™®é€šæ–‡æ¡£ï¼ˆ+0.05 bias æ•ˆæœéªŒè¯ï¼‰
- âœ… RAGAS Faithfulness > 0.80
- âœ… æµ‹è¯•è¦†ç›–ç‡ä¿æŒ 85%+

### é¢è¯•å±•ç¤ºé‡ç‚¹

1. **FAISS é€‰å‹**ï¼š"æˆ‘å¯¹æ¯”äº† ChromaDBã€Weaviate å’Œ FAISSã€‚å¯¹äºæˆ‘çš„åœºæ™¯ï¼ˆå•æœºã€10k-100k æ–‡æ¡£ï¼‰ï¼ŒFAISS çš„ IndexFlatIP è¶³å¤Ÿä¸”æ— é¢å¤–ä¾èµ–ã€‚æˆ‘åšäº† benchmark..."
2. **é•¿æœŸè®°å¿†è®¾è®¡**ï¼š"ä¼ ç»Ÿ RAG åªæ£€ç´¢æ–‡æ¡£ï¼Œæˆ‘åˆ›æ–°åœ°å°†ç”¨æˆ·çš„ç¬”è®°å’Œé”™é¢˜ä¹Ÿå‘é‡åŒ–ã€‚é€šè¿‡ doc_type åŠ æƒï¼Œç³»ç»Ÿä¼šä¼˜å…ˆå›å¿†èµ·æˆ‘ä¹‹å‰çŠ¯è¿‡çš„é”™è¯¯ï¼Œé¿å…é‡å¤è¸©å‘..."
3. **è¯„ä¼°ä½“ç³»**ï¼š"æˆ‘å»ºç«‹äº†å®Œæ•´çš„è¯„ä¼°æµæ°´çº¿ï¼Œæ¯æ¬¡æ”¹åŠ¨éƒ½ä¼šè·‘ RAGAS æŒ‡æ ‡å¯¹æ¯”ã€‚ä» v0.1 åˆ° v0.2ï¼ŒFaithfulness æå‡äº† 12%ï¼Œè¿™å½’åŠŸäºé•¿æœŸè®°å¿†å‡å°‘äº†å¹»è§‰..."

### é£é™©ä¸åº”å¯¹

- **é£é™©**ï¼šFAISS è¿ç§»å¯èƒ½å¯¼è‡´æ•°æ®æ ¼å¼ä¸å…¼å®¹
  - **åº”å¯¹**ï¼šæä¾›è¿ç§»è„šæœ¬ + æ¸…æ™°çš„è¿ç§»æ–‡æ¡£
- **é£é™©**ï¼šLLM ç²¾ç‚¼è®°å¿†çš„æˆæœ¬
  - **åº”å¯¹**ï¼šè®¾ä¸ºå¯é€‰åŠŸèƒ½ï¼Œå¤±è´¥å›é€€åˆ°åŸå§‹å†…å®¹

---

## ğŸŒ v0.3 æ•°æ®æ¥å…¥ + æœç´¢ Agent â­â­â­â­

**ä¼˜å…ˆçº§**ï¼šP1
**å·¥ä½œé‡**ï¼š4-5 å¤©
**é¢è¯•æƒé‡**ï¼šâ­â­â­â­ï¼ˆAgent èƒ½åŠ›å±•ç¤ºï¼‰

### æ ¸å¿ƒç›®æ ‡

1. å¤šæºæ•°æ®æ¥å…¥ï¼ˆURL/GitHubï¼‰
2. å®ç°åŸºç¡€æœç´¢ Agent
3. åŠ¨æ€çŸ¥è¯†åº“æ›´æ–°

### æŠ€æœ¯é€‰å‹ï¼šæ··åˆç­–ç•¥

#### ä¸ºä»€ä¹ˆè¿™é‡Œå¯ä»¥ç”¨æ¡†æ¶ï¼Ÿ

- **æ•°æ®æ¥å…¥**ï¼šLlamaIndex Readers å¤„ç† HTTP/API ç»†èŠ‚ï¼ˆéæ ¸å¿ƒä»·å€¼ï¼‰
- **æœç´¢é€»è¾‘**ï¼šè‡ªå·±å®ç° Agent å†³ç­–å’Œå·¥å…·è°ƒç”¨ï¼ˆæ ¸å¿ƒä»·å€¼ï¼‰
- **æ¯”ä¾‹**ï¼š30% æ¡†æ¶ï¼ˆReadersï¼‰ + 70% Nativeï¼ˆAgent é€»è¾‘ï¼‰

#### å®ç°æ¸…å•

**æ•°æ®æ¥å…¥** (1-2 å¤©)

- [ ] é›†æˆ LlamaIndex Readersï¼ˆæ¡†æ¶éƒ¨åˆ†ï¼‰

  ```python
  # ä»…ç”¨äºæ•°æ®è·å–
  from llama_index.readers import SimpleWebPageReader, GithubRepositoryReader

  def ingest_url(url: str):
      reader = SimpleWebPageReader()
      docs = reader.load_data([url])
      # åç»­å¤„ç†è‡ªå·±å®ç°
      return custom_process_and_chunk(docs)
  ```

- [ ] è‡ªå®šä¹‰åå¤„ç†ï¼ˆNative éƒ¨åˆ†ï¼‰
  ```python
  def custom_process_and_chunk(docs):
      """
      é’ˆå¯¹ä¸åŒå†…å®¹ç±»å‹çš„æ™ºèƒ½åˆ†å—
      - ä»£ç ï¼šæŒ‰å‡½æ•°/ç±»åˆ‡åˆ†
      - æ–‡æ¡£ï¼šæŒ‰è¯­ä¹‰åˆ‡åˆ†
      - è¡¨æ ¼ï¼šç»“æ„åŒ–æå–
      """
      chunks = []
      for doc in docs:
          if is_code(doc):
              chunks.extend(chunk_by_ast(doc))  # ASTè§£æ
          elif is_markdown(doc):
              chunks.extend(chunk_by_header(doc))
          else:
              chunks.extend(semantic_chunking(doc))
      return chunks
  ```
- [ ] ç«™ç‚¹ç™½åå•
  ```python
  ALLOWED_DOMAINS = [
      "pytorch.org",
      "huggingface.co",
      "github.com",
      "arxiv.org"
  ]
  ```

**æœç´¢ Agent å®ç°** (2-3 å¤©) - 100% Native

- [ ] Agent åŸºç¡€æ¡†æ¶

  ```python
  class SearchAgent:
      """
      å†³ç­–é€»è¾‘ï¼š
      1. æœ¬åœ°æ£€ç´¢ç½®ä¿¡åº¦ > 0.7 â†’ ç›´æ¥è¿”å›
      2. ç½®ä¿¡åº¦ < 0.7 â†’ è§¦å‘æœç´¢
      3. æœç´¢ç»“æœ â†’ æ‘˜è¦ â†’ å…¥åº“
      """
      def __init__(self):
          self.tools = {
              'search': self._search_web,
              'fetch': self._fetch_url,
              'summarize': self._summarize
          }

      def decide_and_act(self, query, local_confidence):
          if local_confidence > 0.7:
              return "use_local"

          # æœç´¢å†³ç­–
          search_results = self.tools['search'](query)
          filtered = self._filter_by_whitelist(search_results)

          for url in filtered[:3]:
              content = self.tools['fetch'](url)
              summary = self.tools['summarize'](content)
              self._add_to_vector_store(summary, metadata={
                  'source': url,
                  'ingested_at': datetime.now(),
                  'doc_type': 'web_search'
              })
  ```

- [ ] å·¥å…·å®ç°
  - `_search_web`: é›†æˆ DuckDuckGo API æˆ– SerpAPI
  - `_fetch_url`: requests + BeautifulSoup æ¸…æ´—
  - `_summarize`: è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦

**UI é›†æˆ** (1 å¤©)

- [ ] å¤–ç½‘æœç´¢å¼€å…³ï¼ˆv0.2 å·²å ä½ï¼‰
- [ ] ä¾§è¾¹æ å±•ç¤ºå·² ingest èµ„æ–™
  ```
  ğŸ“š çŸ¥è¯†åº“ (125æ¡)
  â”œâ”€ ğŸ“„ æœ¬åœ°æ–‡æ¡£ (45)
  â”œâ”€ ğŸŒ Webé¡µé¢ (58)
  â”œâ”€ ğŸ’¾ GitHubä»“åº“ (12)
  â”œâ”€ ğŸ“ ç¬”è®° (8)
  â””â”€ âŒ é”™é¢˜ (2)
  ```

### æˆåŠŸæŒ‡æ ‡

- âœ… æˆåŠŸæ¥å…¥ 3 ç§æ•°æ®æºï¼ˆPDF/URL/GitHubï¼‰
- âœ… æœç´¢ Agent è§¦å‘å‡†ç¡®ç‡ > 90%
- âœ… Web å†…å®¹æ‘˜è¦è´¨é‡ï¼ˆäººå·¥è¯„ä¼° 5 åˆ†åˆ¶ > 4 åˆ†ï¼‰
- âœ… ç™½åå•é˜»æ­¢ç‡ 100%ï¼ˆå®‰å…¨æ€§ï¼‰

### é¢è¯•å±•ç¤ºé‡ç‚¹

1. **æ¡†æ¶ä½¿ç”¨åˆ¤æ–­**ï¼š"æ•°æ®æ¥å…¥æˆ‘ç”¨äº† LlamaIndex çš„ Readerï¼Œå› ä¸ºå¤„ç† HTTP å’Œ HTML æ¸…æ´—æ˜¯é€šç”¨é—®é¢˜ã€‚ä½†**chunking ç­–ç•¥æˆ‘è‡ªå·±å®ç°**ï¼Œå› ä¸ºä»£ç å’Œæ–‡æ¡£çš„åˆ‡åˆ†é€»è¾‘å®Œå…¨ä¸åŒâ€”â€”ä»£ç è¦ä¿æŒ AST å®Œæ•´æ€§ï¼Œæ–‡æ¡£è¦æŒ‰è¯­ä¹‰åˆ†å—..."
2. **Agent è®¾è®¡**ï¼š"æˆ‘è®¾è®¡äº†ä¸€ä¸ªç®€å•ä½†æœ‰æ•ˆçš„å†³ç­–æœºåˆ¶ï¼šå½“æœ¬åœ°æ£€ç´¢ç½®ä¿¡åº¦ä½äº 0.7 æ—¶è§¦å‘æœç´¢ã€‚æœç´¢ç»“æœä¼šè‡ªåŠ¨æ‘˜è¦å¹¶æ ‡æ³¨æ¥æºæ—¶é—´ï¼Œå½¢æˆåŠ¨æ€æ›´æ–°çš„çŸ¥è¯†åº“..."
3. **å®‰å…¨æ§åˆ¶**ï¼š"å¤–ç½‘æœç´¢è™½ç„¶é»˜è®¤å¼€å¯ï¼Œä½†æˆ‘å®ç°äº†åŒé‡ä¿æŠ¤ï¼šåŸŸåç™½åå• + ç”¨æˆ·å¯éšæ—¶å…³é—­ã€‚è¿™åœ¨ä¼ä¸šåœºæ™¯å¾ˆé‡è¦..."

---

## ğŸš€ v0.4 é«˜çº§æ£€ç´¢è´¨é‡ä¼˜åŒ– â­â­â­â­â­

**ä¼˜å…ˆçº§**ï¼šP0ï¼ˆä¸ v0.2 å¹¶åˆ—æœ€é«˜ï¼‰
**å·¥ä½œé‡**ï¼š5-6 å¤©
**é¢è¯•æƒé‡**ï¼šâ­â­â­â­â­ï¼ˆæŠ€æœ¯æ·±åº¦æ ¸å¿ƒï¼‰

### æ ¸å¿ƒç›®æ ‡

è¿™æ˜¯å±•ç¤º RAG æŠ€æœ¯æ·±åº¦çš„**æ ¸å¿ƒç‰ˆæœ¬**ï¼Œå…¨éƒ¨è‡ªå·±å®ç°é«˜çº§æ£€ç´¢ç®—æ³•ã€‚

### æŠ€æœ¯é€‰å‹ï¼š95% Native

#### ä¸ºä»€ä¹ˆå‡ ä¹å…¨ Nativeï¼Ÿ

è¿™éƒ¨åˆ†æ˜¯é¢è¯•çš„**æŠ€æœ¯é«˜å…‰æ—¶åˆ»**ï¼Œå¿…é¡»èƒ½æ·±å…¥è®²è§£æ•°å­¦åŸç†å’Œå®ç°ç»†èŠ‚ã€‚

#### å®ç°æ¸…å•

**1. BM25 æ£€ç´¢** (1 å¤©)

```python
# ä½¿ç”¨ç¬¬ä¸‰æ–¹BM25åº“ï¼ˆä¸ç®—æ¡†æ¶ï¼‰
from rank_bm25 import BM25Okapi

class BM25Retriever:
    """
    ç¨€ç–æ£€ç´¢ï¼Œæ“…é•¿å…³é”®è¯åŒ¹é…
    å…¬å¼ï¼šscore = IDF(q) * (f(q,D) * (k1+1)) / (f(q,D) + k1*(1-b+b*|D|/avgDL))
    """
    def __init__(self, corpus, k1=1.5, b=0.75):
        self.bm25 = BM25Okapi(corpus, k1=k1, b=b)
        self.k1 = k1
        self.b = b

    def retrieve(self, query, top_k=20):
        scores = self.bm25.get_scores(tokenize(query))
        return get_top_k(scores, top_k)
```

**2. Hybrid æ£€ç´¢èåˆ** (2 å¤©) - æ ¸å¿ƒç®—æ³•

```python
class HybridRetriever:
    """
    æ··åˆBM25ï¼ˆç¨€ç–ï¼‰å’Œå‘é‡æ£€ç´¢ï¼ˆå¯†é›†ï¼‰
    è§£å†³å„è‡ªçš„çŸ­æ¿ï¼š
    - BM25æ“…é•¿å…³é”®è¯ï¼Œä½†æ— è¯­ä¹‰ç†è§£
    - å‘é‡æ“…é•¿è¯­ä¹‰ï¼Œä½†å…³é”®è¯åŒ¹é…å¼±
    """
    def __init__(self, bm25_retriever, vector_store, alpha=0.7):
        self.bm25 = bm25_retriever
        self.vector = vector_store
        self.alpha = alpha  # å‘é‡æƒé‡ï¼ˆé€šè¿‡è¯„ä¼°é›†è°ƒä¼˜ï¼‰

    def retrieve(self, query, top_k=5):
        # 1. ä¸¤è·¯å¹¶è¡Œæ£€ç´¢
        bm25_results = self.bm25.retrieve(query, top_k=20)
        vector_results = self.vector.search(query, top_k=20)

        # 2. åˆ†æ•°å½’ä¸€åŒ–ï¼ˆå…³é”®ï¼ï¼‰
        bm25_scores = self._normalize(bm25_results)
        vector_scores = self._normalize(vector_results)

        # 3. åŠ æƒèåˆï¼ˆRRFæˆ–çº¿æ€§åŠ æƒï¼‰
        combined = self._reciprocal_rank_fusion(
            bm25_scores, vector_scores
        )
        # æˆ–çº¿æ€§åŠ æƒï¼š
        # combined = alpha * vector_scores + (1-alpha) * bm25_scores

        return combined[:top_k]

    def _reciprocal_rank_fusion(self, results_a, results_b, k=60):
        """
        RRF: score = 1/(k + rank_a) + 1/(k + rank_b)
        æ— éœ€åˆ†æ•°å½’ä¸€åŒ–ï¼Œç›´æ¥ç”¨æ’å
        """
        scores = defaultdict(float)
        for rank, (doc_id, _) in enumerate(results_a):
            scores[doc_id] += 1 / (k + rank + 1)
        for rank, (doc_id, _) in enumerate(results_b):
            scores[doc_id] += 1 / (k + rank + 1)
        return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

**3. Cross-Encoder é‡æ’åº** (1-2 å¤©)

```python
from sentence_transformers import CrossEncoder

class Reranker:
    """
    äºŒé˜¶æ®µæ£€ç´¢ï¼š
    1. Hybridæ£€ç´¢å¬å›top-20ï¼ˆå¿«é€Ÿï¼‰
    2. Cross-Encoderç²¾æ’top-5ï¼ˆæ…¢ä½†å‡†ï¼‰
    """
    def __init__(self, model_name='BAAI/bge-reranker-v2-m3'):
        self.model = CrossEncoder(model_name)

    def rerank(self, query, candidates, top_k=5):
        """
        è®¡ç®—queryå’Œæ¯ä¸ªå€™é€‰çš„ç›¸å…³æ€§åˆ†æ•°
        æ—¶é—´å¤æ‚åº¦ï¼šO(n) - æ¯å¯¹éƒ½è¦è¿‡BERT
        """
        pairs = [(query, doc.text) for doc in candidates]
        scores = self.model.predict(pairs)

        # ç»“åˆåŸå§‹æ£€ç´¢åˆ†æ•°
        for doc, rerank_score in zip(candidates, scores):
            doc.rerank_score = rerank_score

        return sorted(candidates, key=lambda x: x.rerank_score, reverse=True)[:top_k]
```

**4. å…ƒæ•°æ®è¿‡æ»¤ä¸åŠ æƒ** (1 å¤©)

```python
class MetadataAwareRetriever:
    """
    æ ¹æ®å…ƒæ•°æ®åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥
    """
    def retrieve(self, query, filters=None, weights=None):
        # 1. åŸºç¡€æ£€ç´¢
        candidates = self.hybrid_retriever.retrieve(query, top_k=50)

        # 2. å…ƒæ•°æ®è¿‡æ»¤
        if filters:
            candidates = [c for c in candidates if self._match_filters(c, filters)]

        # 3. æ—¶é—´è¡°å‡åŠ æƒ
        for c in candidates:
            age_days = (datetime.now() - c.created_at).days
            time_decay = math.exp(-age_days / 30)  # 30å¤©åŠè¡°æœŸ
            c.score *= time_decay

        # 4. ç±»å‹åŠ æƒï¼ˆv0.2çš„é•¿æœŸè®°å¿†æœºåˆ¶ï¼‰
        if weights:
            for c in candidates:
                if c.doc_type in weights:
                    c.score *= weights[c.doc_type]

        # 5. é‡æ’åº
        return self.reranker.rerank(query, candidates, top_k=5)
```

**5. å®Œæ•´ Pipeline é›†æˆ** (1 å¤©)

```python
class AdvancedRAGPipeline:
    def __init__(self):
        self.bm25 = BM25Retriever(...)
        self.vector_store = FaissVectorStore(...)
        self.hybrid = HybridRetriever(self.bm25, self.vector_store, alpha=0.72)
        self.reranker = Reranker()
        self.metadata_retriever = MetadataAwareRetriever(self.hybrid, self.reranker)

    def query(self, question, filters=None):
        # 1. æ£€ç´¢
        chunks = self.metadata_retriever.retrieve(
            question,
            filters=filters,
            weights={'note': 1.2, 'mistake': 1.5, 'document': 1.0}
        )

        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(chunks)

        # 3. ç”Ÿæˆç­”æ¡ˆ
        answer = self.llm.generate(question, context)

        return {
            'answer': answer,
            'sources': [c.source for c in chunks],
            'debug': {
                'retrieval_scores': [c.score for c in chunks],
                'rerank_scores': [c.rerank_score for c in chunks]
            }
        }
```

### è¯„ä¼°è®¡åˆ’

åœ¨ `docs/experiments.md` è®°å½•å¯¹æ¯”å®éªŒï¼š

| ç­–ç•¥                   | Hit@5    | RAGAS<br>Context<br>Recall | RAGAS<br>Faithfulness | P95<br>Latency | å¤‡æ³¨               |
| ---------------------- | -------- | -------------------------- | --------------------- | -------------- | ------------------ |
| Baseline (v0.2 çº¯å‘é‡) | 0.68     | 0.72                       | 0.80                  | 450ms          | -                  |
| +BM25 æ··åˆ             | 0.75     | 0.78                       | 0.82                  | 520ms          | alpha=0.7          |
| +RRF èåˆ              | 0.77     | 0.80                       | 0.83                  | 530ms          | k=60               |
| +Cross-Encoder         | **0.85** | **0.88**                   | **0.89**              | 1100ms         | bge-reranker-v2-m3 |
| +å…ƒæ•°æ®åŠ æƒ            | **0.87** | **0.90**                   | **0.90**              | 1150ms         | æ—¶é—´è¡°å‡+ç±»å‹æƒé‡  |

### æˆåŠŸæŒ‡æ ‡

- âœ… Hit@5 > 0.85ï¼ˆç›¸æ¯” v0.2 æå‡ >15%ï¼‰
- âœ… RAGAS Context Recall > 0.88
- âœ… P95 Latency < 1500msï¼ˆå¯æ¥å—çš„å»¶è¿Ÿå¢åŠ ï¼‰
- âœ… èƒ½æ¸…æ™°è®²è§£æ¯ä¸ªç®—æ³•çš„æ•°å­¦åŸç†

### é¢è¯•å±•ç¤ºé‡ç‚¹ï¼ˆæ ¸å¿ƒï¼ï¼‰

**1. Hybrid Search æ·±åº¦è®²è§£**

> "çº¯å‘é‡æ£€ç´¢åœ¨å…³é”®è¯åŒ¹é…ä¸Šæœ‰å¼±ç‚¹ï¼Œæ¯”å¦‚æŸ¥'PyTorch 2.0 æ–°ç‰¹æ€§'ï¼Œå¦‚æœæ–‡æ¡£é‡Œæ˜¯'PyTorch version 2.0 features'ï¼Œè¯­ä¹‰ç›¸è¿‘ä½†å‘é‡è·ç¦»å¯èƒ½ä¸æ˜¯æœ€ä¼˜ã€‚BM25 èƒ½ç²¾å‡†åŒ¹é…'PyTorch'å’Œ'2.0'è¿™äº›å…³é”®è¯ã€‚
>
> æˆ‘å®ç°äº† RRFï¼ˆReciprocal Rank Fusionï¼‰èåˆç­–ç•¥ï¼Œå…¬å¼æ˜¯ score = 1/(k+rank)ã€‚ç›¸æ¯”çº¿æ€§åŠ æƒï¼ŒRRF çš„ä¼˜åŠ¿æ˜¯ä¸éœ€è¦å½’ä¸€åŒ–åˆ†æ•°ï¼Œç›´æ¥ç”¨æ’åï¼Œæ›´é²æ£’..."

**2. å‚æ•°è°ƒä¼˜è¿‡ç¨‹**

> "æˆ‘é€šè¿‡è¯„ä¼°é›†è°ƒä¼˜äº†ä¸¤ä¸ªå…³é”®å‚æ•°ï¼š
>
> - Hybrid çš„ alpha æƒé‡ï¼šæµ‹è¯•äº† 0.5-0.9ï¼Œå‘ç° 0.72 æ—¶ Hit@5 æœ€é«˜
> - RRF çš„ k å€¼ï¼šæµ‹è¯•äº† 30/60/100ï¼Œk=60 å¹³è¡¡äº†ä¸¤è·¯æ£€ç´¢çš„è´¡çŒ®åº¦
>
> è¿™äº›éƒ½è®°å½•åœ¨`experiments.md`é‡Œï¼Œæœ‰å®Œæ•´çš„æ¶ˆèå®éªŒ..."

**3. å»¶è¿Ÿ vs è´¨é‡æƒè¡¡**

> "Cross-Encoder è®©å»¶è¿Ÿä» 450ms å¢åŠ åˆ° 1100msï¼Œä½†å‡†ç¡®ç‡æå‡äº† 17 ä¸ªç™¾åˆ†ç‚¹ã€‚å¯¹äºå­¦ä¹ åœºæ™¯ï¼Œç”¨æˆ·æ›´åœ¨æ„ç­”æ¡ˆè´¨é‡è€Œéå®æ—¶æ€§ï¼Œæ‰€ä»¥è¿™ä¸ª trade-off æ˜¯å€¼å¾—çš„ã€‚
>
> æœªæ¥ä¼˜åŒ–æ–¹å‘å¯ä»¥è€ƒè™‘ï¼š
>
> - å¼‚æ­¥é‡æ’åºï¼ˆå…ˆè¿”å› Hybrid ç»“æœï¼Œåå°é‡æ’ï¼‰
> - ç¼“å­˜çƒ­é—¨ query çš„é‡æ’åºç»“æœ
> - ä½¿ç”¨æ›´å¿«çš„è½»é‡çº§ reranker"

---

## ğŸ“ v0.5 å­¦ä¹ æ¨¡å¼ + LangGraph ç¼–æ’ â­â­â­

**ä¼˜å…ˆçº§**ï¼šP2ï¼ˆå¯é€‰ï¼‰
**å·¥ä½œé‡**ï¼š4-5 å¤©
**é¢è¯•æƒé‡**ï¼šâ­â­â­ï¼ˆå±•ç¤ºæ¡†æ¶ä½¿ç”¨åˆ¤æ–­ï¼‰

### æ ¸å¿ƒç›®æ ‡

å®ç°å¤æ‚çš„å¤šæ­¥éª¤å·¥ä½œæµï¼Œå±•ç¤º"ä½•æ—¶ç”¨æ¡†æ¶"çš„åˆ¤æ–­åŠ›ã€‚

### æŠ€æœ¯é€‰å‹ï¼šå¼•å…¥ LangGraph

#### ä¸ºä»€ä¹ˆè¿™é‡Œç”¨æ¡†æ¶åˆé€‚ï¼Ÿ

- **å¤æ‚åº¦**ï¼šå¤šæ¨¡å¼åˆ‡æ¢ã€çŠ¶æ€ç®¡ç†ï¼ˆ>500 LOC è‡ªå·±å®ç°ï¼‰
- **æ¡†æ¶ä¼˜åŠ¿**ï¼šLangGraph ä¸“é—¨ä¸ºæ­¤è®¾è®¡ï¼Œæœ‰å¯è§†åŒ–è°ƒè¯•
- **ä¸å½±å“æ ¸å¿ƒ**ï¼šv0.2-v0.4 çš„ RAG é€»è¾‘ä»æ˜¯è‡ªå·±çš„
- **å±•ç¤ºåˆ¤æ–­åŠ›**ï¼šè¯æ˜ä½ çŸ¥é“"ä½•æ—¶é€ è½®å­ã€ä½•æ—¶ç”¨è½®å­"

### å®ç°æ¸…å•

**å­¦ä¹ æ¨¡å¼çŠ¶æ€æœº** (2-3 å¤©)

```python
from langgraph.graph import StateGraph, END

class LearningModeWorkflow:
    """
    å­¦ä¹ æ¨¡å¼æµç¨‹ï¼š
    ç†è§£æ¦‚å¿µ â†’ åˆ¶å®šè®¡åˆ’ â†’ æ¨èèµ„æ–™ â†’ ç”Ÿæˆç»ƒä¹  â†’ è¯„ä¼°ç†è§£
    """
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline  # ä½¿ç”¨v0.4çš„æ£€ç´¢pipeline
        self.graph = self._build_graph()

    def _build_graph(self):
        workflow = StateGraph(State)

        # å®šä¹‰èŠ‚ç‚¹ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ä»ç”¨è‡ªå·±çš„RAGï¼‰
        workflow.add_node("understand", self._understand_concept)
        workflow.add_node("plan", self._create_learning_plan)
        workflow.add_node("resources", self._recommend_resources)
        workflow.add_node("practice", self._generate_practice)

        # å®šä¹‰è¾¹
        workflow.add_edge("understand", "plan")
        workflow.add_edge("plan", "resources")
        workflow.add_conditional_edges(
            "resources",
            self._should_practice,
            {
                "yes": "practice",
                "no": END
            }
        )

        workflow.set_entry_point("understand")
        return workflow.compile()

    def _understand_concept(self, state):
        """ä½¿ç”¨è‡ªå·±çš„RAGæ£€ç´¢ç›¸å…³æ¦‚å¿µ"""
        concept = state['query']
        chunks = self.rag.metadata_retriever.retrieve(
            f"explain {concept}",
            filters={'doc_type': ['document', 'note']}
        )
        explanation = self.rag.llm.generate(
            f"Explain {concept} based on:\n{chunks}"
        )
        state['explanation'] = explanation
        return state
```

**é—®é¢˜è§£å†³æ¨¡å¼** (1-2 å¤©)

```python
class ProblemSolvingWorkflow:
    """
    é—®é¢˜è§£å†³æµç¨‹ï¼š
    åˆ†æé”™è¯¯ â†’ æ£€ç´¢ç›¸ä¼¼é”™è¯¯ â†’ ç”Ÿæˆè§£å†³æ–¹æ¡ˆ â†’ æ ‡è®°ä¸ºé”™é¢˜
    """
    def _analyze_error(self, state):
        error_log = state['error_log']
        # æ£€ç´¢å†å²é”™é¢˜
        similar_mistakes = self.rag.metadata_retriever.retrieve(
            error_log,
            filters={'doc_type': 'mistake'},
            weights={'mistake': 2.0}  # é«˜æƒé‡å†å²é”™è¯¯
        )
        # ...
```

### é¢è¯•å±•ç¤ºé‡ç‚¹

> "å‰é¢çš„æ ¸å¿ƒ RAG æˆ‘éƒ½æ˜¯è‡ªå·±å®ç°çš„ï¼Œä½†åˆ°äº†å¤æ‚å·¥ä½œæµç¼–æ’ï¼Œæˆ‘å¼•å…¥äº† LangGraphã€‚åŸå› æœ‰ä¸‰ï¼š
>
> 1. çŠ¶æ€ç®¡ç†å¤æ‚åº¦é«˜ï¼ˆå¤šæ¨¡å¼ã€æ¡ä»¶è·³è½¬ï¼‰
> 2. LangGraph æä¾›å¯è§†åŒ–è°ƒè¯•ï¼Œæé«˜å¼€å‘æ•ˆç‡
> 3. å…³é”®æ˜¯**æˆ‘çš„æ£€ç´¢é€»è¾‘ä»ç„¶ç”¨ v0.4 è‡ªå·±å®ç°çš„ Hybrid+Rerank**ï¼Œæ¡†æ¶åªè´Ÿè´£ç¼–æ’
>
> è¿™ä½“ç°äº†æˆ‘çš„åˆ¤æ–­ï¼šæ ¸å¿ƒç®—æ³•è‡ªå·±æŒæ§ï¼Œå¤–å›´å·¥å…·åˆç†ä½¿ç”¨ã€‚"

---

## ğŸ“Š v0.6 ç›‘æ§ + æ•°æ®é—­ç¯ â­â­

**ä¼˜å…ˆçº§**ï¼šP3ï¼ˆæ—¶é—´å……è£•å¯åšï¼‰
**å·¥ä½œé‡**ï¼š3-4 å¤©
**é¢è¯•æƒé‡**ï¼šâ­â­ï¼ˆåŠ åˆ†é¡¹ï¼‰

### å®ç°æ¸…å•

- [ ] é›†æˆ LangSmith/LangFuse åš trace å¯è§†åŒ–
- [ ] Prometheus metrics å¯¼å‡º
- [ ] ç”¨æˆ·åé¦ˆæ”¶é›†ç•Œé¢
- [ ] ï¼ˆå¯é€‰ï¼‰å¾®è°ƒæ•°æ®æ”¶é›† pipeline

---

## ğŸ“ˆ è¯„ä¼°ä¸è´¨é‡ä¿è¯

### æ¯ä¸ªç‰ˆæœ¬çš„è¯„ä¼°æµç¨‹

1. **è¿è¡Œè¯„ä¼°è„šæœ¬**

   ```bash
   python evaluate.py --dataset tests/data/evaluation_dataset.json
   ```

2. **è®°å½•åˆ° experiments.md**

   ```markdown
   ## v0.4 Hybrid Search å®éªŒ (2025-01-20)

   ### é…ç½®

   - Model: gpt-4.1-nano
   - Retrieval: BM25(k1=1.5, b=0.75) + FAISS(dim=1536) + RRF(k=60)
   - Reranker: bge-reranker-v2-m3

   ### ç»“æœ

   | æŒ‡æ ‡               | v0.2 Baseline | v0.4 | æå‡ |
   | ------------------ | ------------- | ---- | ---- |
   | Hit@5              | 0.68          | 0.85 | +25% |
   | RAGAS Faithfulness | 0.80          | 0.89 | +11% |

   ### ç»“è®º

   RRF èåˆæ•ˆæœä¼˜äºçº¿æ€§åŠ æƒï¼Œalpha å‚æ•°å¯¹ç»“æœå½±å“æ˜¾è‘—...
   ```

3. **æ›´æ–° DEVLOG.md**
   è®°å½•å†³ç­–è¿‡ç¨‹ã€é‡åˆ°çš„å‘ã€è§£å†³æ–¹æ¡ˆ

---

## ğŸ¯ é¢è¯•å‡†å¤‡æ¸…å•

### 3 åˆ†é’Ÿç”µæ¢¯æ¼”è®²

```
æˆ‘å¼€å‘äº†LCEngineï¼Œä¸€ä¸ªå·¥ä¸šçº§çš„RAGå­¦ä¹ åŠ©æ‰‹ã€‚

ã€é—®é¢˜ã€‘ï¼šé€šç”¨LLMåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸå®¹æ˜“å¹»è§‰ï¼Œä¸”æ— æ³•è®°ä½æˆ‘çš„å­¦ä¹ è¿›åº¦ã€‚

ã€æ–¹æ¡ˆã€‘ï¼šæˆ‘å®ç°äº†ä¸‰ä¸ªæ ¸å¿ƒåˆ›æ–°ï¼š
1. Hybridæ£€ç´¢ï¼ˆBM25+å‘é‡+é‡æ’åºï¼‰ï¼Œå‡†ç¡®ç‡æå‡25%
2. é•¿æœŸè®°å¿†æœºåˆ¶ï¼ˆç¬”è®°/é”™é¢˜å‘é‡åŒ–ï¼‰ï¼Œé¿å…é‡å¤è¸©å‘
3. å®Œæ•´è¯„ä¼°ä½“ç³»ï¼ˆRAGAS+è‡ªå®šä¹‰æŒ‡æ ‡ï¼‰ï¼Œæ¯æ¬¡æ”¹åŠ¨éƒ½æœ‰æ•°æ®æ”¯æ’‘

ã€æŠ€æœ¯äº®ç‚¹ã€‘ï¼š
- æ ¸å¿ƒç®—æ³•70%è‡ªå·±å®ç°ï¼Œå±•ç¤ºæ·±åº¦ç†è§£
- 30%åˆç†ä½¿ç”¨æ¡†æ¶ï¼ˆæ•°æ®æ¥å…¥/å¤æ‚ç¼–æ’ï¼‰ï¼Œå±•ç¤ºå·¥ç¨‹åˆ¤æ–­
- å®Œæ•´çš„æµ‹è¯•ï¼ˆ85%è¦†ç›–ï¼‰ã€è¯„ä¼°ã€æ–‡æ¡£ä½“ç³»

ã€æˆæœã€‘ï¼šä»v0.1åˆ°v0.4ï¼Œæ£€ç´¢å‡†ç¡®ç‡ä»68%æå‡åˆ°87%ï¼Œ
        è¿™äº›æå‡éƒ½è®°å½•åœ¨æˆ‘çš„experiments.mdä¸­...
```

### Demo è„šæœ¬å‡†å¤‡

åˆ›å»º `docs/demo_script.md`ï¼ŒåŒ…å«ï¼š

1. åœºæ™¯æ¼”ç¤ºï¼ˆ5 åˆ†é’Ÿï¼‰
2. ä»£ç  walk-throughï¼ˆ5 åˆ†é’Ÿï¼‰
3. æŒ‡æ ‡å¯¹æ¯”å±•ç¤ºï¼ˆ2 åˆ†é’Ÿï¼‰

### å…³é”®é—®é¢˜å‡†å¤‡

1. "ä¸ºä»€ä¹ˆä¸ç”¨ LangChainï¼Ÿ" â†’ å·²å‡†å¤‡
2. "å¦‚æœæ•°æ®é‡å¢é•¿åˆ° 1000 ä¸‡æ–‡æ¡£æ€ä¹ˆåŠï¼Ÿ" â†’ æ‰©å±•æ–¹æ¡ˆ
3. "å¦‚ä½•é˜²æ­¢å¹»è§‰ï¼Ÿ" â†’ Faithfulness æŒ‡æ ‡ + æ¥æºæ ‡æ³¨
4. "æˆæœ¬å¦‚ä½•æ§åˆ¶ï¼Ÿ" â†’ Embedding ç¼“å­˜ + æ¨¡å‹é™çº§ç­–ç•¥

---

## ğŸ“… æ—¶é—´çº¿å»ºè®®

### æœ€å°å¯é¢è¯•ç‰ˆæœ¬ï¼ˆ2 å‘¨ï¼‰

- Week 1: v0.2 å®Œæ•´å®ç°
- Week 2: v0.4 å®Œæ•´å®ç°
- **æˆæœ**ï¼šæ ¸å¿ƒ RAG è´¨é‡ä¼˜ç§€ï¼Œè¶³ä»¥é¢è¯•

### ç†æƒ³ç‰ˆæœ¬ï¼ˆ3 å‘¨ï¼‰

- Week 1: v0.2
- Week 2: v0.3 + v0.4 å‰åŠéƒ¨åˆ†
- Week 3: v0.4 å®Œæˆ + æ–‡æ¡£/Demo å‡†å¤‡
- **æˆæœ**ï¼šå®Œæ•´èƒ½åŠ›å±•ç¤º

### å®Œæ•´ç‰ˆæœ¬ï¼ˆ4 å‘¨ï¼‰

- å‰ 3 å‘¨åŒä¸Š
- Week 4: v0.5ï¼ˆå¯é€‰ï¼‰+ v0.6 ç›‘æ§ + å®Œå–„æ–‡æ¡£
- **æˆæœ**ï¼šå·¥ä¸šçº§å®Œæ•´åº¦

---

## ğŸ“ å­¦ä¹ èµ„æº

### æ¨èé˜…è¯»

- RAGAS è®ºæ–‡åŠæ–‡æ¡£
- FAISS å®˜æ–¹æ–‡æ¡£
- BGE Reranker æŠ€æœ¯æŠ¥å‘Š
- LangGraph æ•™ç¨‹ï¼ˆv0.5 ä½¿ç”¨ï¼‰

### å¯¹æ¯”é¡¹ç›®ç ”ç©¶

- LlamaIndex å®˜æ–¹ç¤ºä¾‹
- LangChain RAG æ•™ç¨‹
- åˆ†æå®ƒä»¬çš„ä¼˜ç¼ºç‚¹ï¼Œå‡†å¤‡é¢è¯•å¯¹æ¯”è®¨è®º

---

**æ€»ç»“**ï¼šè¿™ä¸ªè·¯çº¿å›¾çš„æ ¸å¿ƒç­–ç•¥æ˜¯**"åœ¨å±•ç¤ºæ·±åº¦çš„åœ°æ–¹ Native å®ç°ï¼Œåœ¨æé«˜æ•ˆç‡çš„åœ°æ–¹åˆç†ä½¿ç”¨æ¡†æ¶"**ã€‚å®Œæˆ v0.2+v0.4 åï¼Œä½ å°†æ‹¥æœ‰ä¸€ä¸ªèƒ½æ·±å…¥è®²è§£æŠ€æœ¯ç»†èŠ‚ã€åˆæœ‰å®Œæ•´å·¥ç¨‹å®è·µçš„é¢è¯•é¡¹ç›®ã€‚
